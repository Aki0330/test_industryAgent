import streamlit as st
import pandas as pd
from agent.supply_chain_agent import SupplyChainAgent
from agent.regional_agent import RegionalAgent
from agent.industry_agent import IndustryAgent  # ç¡®ä¿è·¯å¾„æ­£ç¡®
import tempfile
import os

st.set_page_config(page_title="è¡Œä¸šæ™ºèƒ½åˆ†æ", layout="wide")

st.title("è¡Œä¸šæ™ºèƒ½åˆ†æåŠ©æ‰‹")

# Tabåˆ‡æ¢ï¼šè¡Œä¸šåˆ†æ/åœ°åŒºåˆ†æ
#tabs = st.tabs(["ä¾›åº”é“¾åˆ†æ", "åœ°åŒºåˆ†æ"])
tabs = st.tabs(["ä¾›åº”é“¾åˆ†æ", "åœ°åŒºåˆ†æ", "è¡Œä¸šæŠ¥å‘Šåˆ†æ"])

# ========== è¡Œä¸šåˆ†æ Tab ==========
with tabs[0]:
    st.write("è¯·ä¸Šä¼ åŒ…å«ä¼ä¸šå› å­å’Œå…³è”æƒé‡çš„CSVæ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œä¾›åº”é“¾&ä¸Šä¸‹æ¸¸è¶‹åŠ¿åˆ†æå’Œé¢„æµ‹ã€‚")
    uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type=["csv"], key="industry_csv")
    if uploaded_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        df = pd.read_csv(tmp_path)
        st.subheader("æ•°æ®é¢„è§ˆ")
        st.dataframe(df)
        st.subheader("ä¾›åº”é“¾åˆ†ææŠ¥å‘Š")
        with st.spinner("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™..."):
            agent = SupplyChainAgent()
            report, graph_img_path = agent.analyze(tmp_path)
        st.success("åˆ†æå®Œæˆï¼")
        st.markdown(f"```\n{report}\n```")
        # å¯é€‰ï¼šå±•ç¤ºè¡Œä¸šå…³ç³»å›¾
        # st.subheader("ä¼ä¸šå…³ç³»å›¾å¯è§†åŒ–")
        # st.image(graph_img_path, caption="è¡Œä¸šä¼ä¸šå…³ç³»å›¾")
    else:
        st.info("è¯·å…ˆä¸Šä¼ CSVæ–‡ä»¶ã€‚")

# ========== åœ°åŒºåˆ†æ Tab ==========
with tabs[1]:
    st.write("è¯·ä¸Šä¼ åŒä¸€åœ°åŒºçš„ä¼ä¸šjsonæŠ¥å‘Šæ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰ï¼Œå¹¶è¾“å…¥åœ°åŒºåç§°ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œåœ°åŒºçº§ä¼ä¸šç½‘ç»œä¸é›†ç¾¤åˆ†æã€‚")
    uploaded_jsons = st.file_uploader("ä¸Šä¼ ä¼ä¸šjsonæŠ¥å‘Šï¼ˆå¯å¤šé€‰ï¼‰", type=["json"], accept_multiple_files=True, key="region_jsons")
    region_name = st.text_input("è¯·è¾“å…¥åœ°åŒºåç§°ï¼ˆå¦‚ï¼šä¸­å›½ï¼ŒåŒ—äº¬å¸‚ï¼‰", value="ä¸­å›½ï¼ŒåŒ—äº¬å¸‚")
    if uploaded_jsons and region_name:
        # å°†ä¸Šä¼ çš„jsonæ–‡ä»¶ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as tmp_dir:
            file_paths = []
            for file in uploaded_jsons:
                file_path = os.path.join(tmp_dir, file.name)
                with open(file_path, "wb") as f:
                    f.write(file.getvalue())
                file_paths.append(file_path)
            st.write(f"å·²ä¸Šä¼  {len(file_paths)} ä»½ä¼ä¸šjsonæŠ¥å‘Š")
            # è°ƒç”¨RegionalAgentåˆ†æ
            with st.spinner("æ­£åœ¨è¿›è¡Œåœ°åŒºåˆ†æï¼Œè¯·ç¨å€™..."):
                agent = RegionalAgent()
                # ç›´æ¥ä¼ é€’ä¸´æ—¶ç›®å½•
                report = agent.analyze_region(tmp_dir, region_name)
            if report:
                st.success("åˆ†æå®Œæˆï¼")
                st.subheader("åœ°åŒºåˆ†æä¸»è¦ç»“è®º")
                st.markdown(f"**å…¬å¸æ•°é‡ï¼š** {report.get('companies_count', 0)}")
                st.markdown(f"**äº§ä¸šåˆ†å¸ƒï¼š** {report.get('industry_distribution', {})}")
                st.markdown(f"**äº§ä¸šé›†ç¾¤å¼ºåº¦ï¼š** {report.get('regional_insights', {}).get('economic_cluster_strength', {}).get('strength_level', 'æœªçŸ¥')}")
                st.markdown(f"**åˆ›æ–°æ½œåŠ›ï¼š** {report.get('regional_insights', {}).get('innovation_potential', {}).get('potential_level', 'æœªçŸ¥')}")
                st.markdown(f"**ååŒåˆ†æ•°ï¼š** {report.get('network_analysis', {}).get('synergy_score', 'æ— ')}")
                st.markdown(f"**æ¢çº½ä¼ä¸šï¼š** {report.get('network_analysis', {}).get('hub_companies', [])}")
                st.markdown(f"**æŠ•èµ„å»ºè®®ï¼š** {report.get('investment_recommendations', {}).get('recommendation_level', 'æœªçŸ¥')}")
                
                # å±•ç¤ºLLMç”Ÿæˆçš„æ™ºèƒ½åˆ†ææŠ¥å‘Š
                if 'llm_report' in report:
                    st.subheader("AIæ™ºèƒ½åˆ†ææŠ¥å‘Š")
                    st.markdown(report['llm_report'])
                
                # å±•ç¤ºç½‘ç»œå›¾
                graph_img = report.get('network_analysis', {}).get('graph_image', None)
                if graph_img and os.path.exists(graph_img):
                    st.subheader("ä¼ä¸šç½‘ç»œå…³ç³»å›¾ï¼ˆç²¾ç®€ç‰ˆï¼‰")
                    st.image(graph_img, caption="åœ°åŒºä¼ä¸šå…³ç³»ç½‘ç»œ")
                # æä¾›txtæŠ¥å‘Šä¸‹è½½
                txt_path = f"regional_report_{region_name.replace('ï¼Œ','_')}.txt"
                if os.path.exists(txt_path):
                    with open(txt_path, "r", encoding="utf-8") as f:
                        txt_content = f.read()
                    st.subheader("åˆ†ææŠ¥å‘Šæ–‡æœ¬ï¼ˆå¯å¤åˆ¶/ä¸‹è½½ï¼‰")
                    st.text_area("åœ°åŒºåˆ†ææŠ¥å‘Š", txt_content, height=400)
                    st.download_button("ä¸‹è½½txtæŠ¥å‘Š", txt_content, file_name=txt_path)
            else:
                st.error("æœªç”Ÿæˆåœ°åŒºåˆ†ææŠ¥å‘Šï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å†…å®¹ã€‚")
    else:
        st.info("è¯·ä¸Šä¼ ä¼ä¸šjsonæŠ¥å‘Šå¹¶è¾“å…¥åœ°åŒºåç§°ã€‚")

# ========== è¡Œä¸šæŠ¥å‘Šåˆ†æ Tab ==========ï¼ˆåŸºäº IndustryAgentï¼‰
with tabs[2]:
    st.write("è¯·ä¸Šä¼ ä¸€ä¸ªè¡Œä¸šä¸‹å¤šä¸ªå…¬å¸çš„JSONæ ¼å¼æŠ¥å‘Šæ–‡ä»¶ï¼Œå¹¶æŒ‡å®šè¡Œä¸šåç§°ï¼Œç³»ç»Ÿå°†ç”Ÿæˆè¡Œä¸šç»“æ„åˆ†æåŠæ™ºèƒ½æ‘˜è¦ã€‚")

    uploaded_jsons = st.file_uploader("ä¸Šä¼ è¡Œä¸šå…¬å¸æŠ¥å‘Šï¼ˆæ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼‰", type=["json"], accept_multiple_files=True, key="industry_jsons")
    industry_name = st.text_input("è¯·è¾“å…¥è¡Œä¸šåç§°ï¼ˆå¦‚ï¼šè¯åˆ¸ã€æ–°èƒ½æºã€äººå·¥æ™ºèƒ½ç­‰ï¼‰", value="è¯åˆ¸")

    if uploaded_jsons and industry_name:
        # ä¿å­˜ä¸Šä¼ æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as tmp_dir:
            file_paths = []
            for file in uploaded_jsons:
                file_path = os.path.join(tmp_dir, file.name)
                with open(file_path, "wb") as f:
                    f.write(file.getvalue())
                file_paths.append(file_path)

            st.write(f"å·²ä¸Šä¼  {len(file_paths)} ä¸ªè¡Œä¸šæŠ¥å‘Šæ–‡ä»¶")
            output_json_path = os.path.join(tmp_dir, f"{industry_name}_industry_report.json")

            with st.spinner("æ­£åœ¨ç”Ÿæˆè¡Œä¸šåˆ†ææŠ¥å‘Šï¼Œè¯·ç¨å€™..."):
                agent = IndustryAgent()
                report = agent.analyze_industry(
                    industry_dir=tmp_dir,
                    industry_name=industry_name,
                    output_path=output_json_path
                )

            if report:
                st.success("è¡Œä¸šåˆ†æå®Œæˆï¼")
                st.markdown(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š`{output_json_path}`")

                # å±•ç¤ºç»“æ„åŒ–æ•°æ®
                st.subheader("è¡Œä¸šç»“æ„æ‘˜è¦")
                st.markdown(f"**è¡Œä¸šåç§°ï¼š** {report.get('industry_name', 'æœªçŸ¥')}")
                #st.markdown(f"**å…¬å¸æ•°é‡ï¼š** {len(report.get('company_reports', []))}")
                st.markdown(f"**å…¬å¸æ•°é‡ï¼š** {report.get('companies_count', 0)}")
                #st.markdown(f"**ä¸»è¦ç»“è®ºï¼š** {report.get('summary', 'æ— ')}")

                # å±•ç¤ºLLMæŠ¥å‘Š
                if "llm_report" in report:
                    st.subheader("LLMæ™ºèƒ½åˆ†ææŠ¥å‘Š")
                    st.markdown(report["llm_report"])

                # å°è¯•è¯»å–TXTæŠ¥å‘Š
                txt_path = output_json_path.replace(".json", ".txt")
                if os.path.exists(txt_path):
                    with open(txt_path, "r", encoding="utf-8") as f:
                        txt_content = f.read()
                    st.subheader("åˆ†ææŠ¥å‘Šæ–‡æœ¬ï¼ˆå¯å¤åˆ¶/ä¸‹è½½ï¼‰")
                    st.text_area("è¡Œä¸šåˆ†ææŠ¥å‘Š", txt_content, height=400)
                    st.download_button("ä¸‹è½½txtæŠ¥å‘Š", txt_content, file_name=os.path.basename(txt_path))
            else:
                st.error("æœªç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œè¯·æ£€æŸ¥ä¸Šä¼ çš„JSONæ–‡ä»¶æ˜¯å¦æ ¼å¼æ­£ç¡®ã€‚")
    else:
        st.info("è¯·ä¸Šä¼ è¡Œä¸šæŠ¥å‘Šå¹¶è¾“å…¥è¡Œä¸šåç§°ã€‚")



#streamlit run web_app.py